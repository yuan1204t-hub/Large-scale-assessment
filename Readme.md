Large-scale assessment of regression modeling practices in phytomedicine extraction process optimization

ğŸ“Œ Introduction
This repository provides a systematic Python-based framework for evaluating the normality and stability of modeling methods used in Traditional Chinese Medicine (TCM) extraction process optimization. Unlike traditional approaches, this toolkit focuses on ensuring statistical rigor and quantifying process robustness through advanced subset selection and stability metrics.

ğŸ“‚ Repository Structure
The project is organized into four main modules following the research workflow:

    ğŸ“ 01_Data_Preprocessing
    Purpose: Cleaning and digitizing raw experimental data.
    Content: Scripts for handling missing values and preparing datasets for batch regression.

    ğŸ“ 02_Regression_Analysis
    Purpose: Normality diagnostics and alternative ANOVA testing.
    Content: Automated workflows to perform Kruskal-Wallis H-test or Welch's ANOVA when standard OLS assumptions (normality/homogeneity of variance) are violated.
    
    ğŸ“ 03_Global_Optimization
    Purpose: Optimal model selection and residual validation.
    Content:
        Full-subset search for Model 1 (M1) based on $R_c^2$ maximization.
        Structural optimization for Model 2 (M2) using Mallows' $C_r$ criterion.
        Residual diagnostic suite to ensure model unbiasedness.
    
    ğŸ“ 04_Stability_Analysis
    Purpose: Quantifying process advice reliability via Coefficient of Variation (CV).
    Content:
        Global grid search for theoretical process peaks (Ymax) and factor settings.
        CV Calculation: Stability assessment using Z-normalized response variables and raw factor levels to evaluate reproducibility across different experimental conditions.
        
    ğŸ“ Data
    Purpose: Central archive for the complete original dataset.
    Content: Contains data.zip, which includes all raw experimental matrices required by the scripts and a comprehensive summary table from the original manuscript.

ğŸ“Š Dataset Availability & Usage
The complete raw dataset supporting this study is securely archived in /Data/Data.zip.

    To reproduce our study: Simply extract data.zip, and update the input paths in the Python scripts to point to the unzipped directories.

    To analyze your own data: You are highly encouraged to use this framework for your own research. Just format your datasets to match the structure provided in Data and modify the paths accordingly.

âš™ï¸ Execution Workflow
This framework operates as a highly integrated pipeline. Because subsequent scripts rely on the intermediate data and standardized formats generated by preceding modules, you must execute the scripts strictly in sequential order (i.e., 01 â” 02 â” 03 â” 04).

ğŸ›  Installation & Requirements
Ensure you have Python 3.8+ installed. Install the necessary dependencies via:

pip install -r requirements.txt

ğŸš€ Usage Note: Path Configuration
[!IMPORTANT]
Before running any script, you must manually update the Input/Output file paths within the Python files to match your local directory structure. Look for the # Path Configuration block at the bottom of each script (typically inside if __name__ == "__main__":).

ğŸ“ Citation
If you use this code in your research, please cite:
[Yuan Tao]. (2026). Large-scale assessment of regression modeling practices in phytomedicine extraction process optimization. [iScience]. DOI: 10.5281/zenodo.XXXXXXX

ğŸ“„ License
This project is licensed under the MIT License.